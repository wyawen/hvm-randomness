{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_estimator(pred_class_list, correct_class_list, no_harvest):\n",
    "    total_classes = 10\n",
    "    total_cost = 0\n",
    "    total_data_count = len(pred_class_list)\n",
    "    valid_data_count = 0\n",
    "    for i in range(total_data_count):\n",
    "        pred_class = pred_class_list[i]\n",
    "        correct_class = correct_class_list[i]\n",
    "        if pred_class > correct_class or pred_class == 10 or no_harvest:\n",
    "            if pred_class<correct_class:\n",
    "                cost = correct_class-pred_class+total_classes\n",
    "            else:\n",
    "                cost = pred_class-correct_class\n",
    "            total_cost += cost\n",
    "            valid_data_count += 1\n",
    "            #print \"[pred,target,cost]: [{},{},{}]\".format(pred_class, correct_class, cost)\n",
    "    print \"total valid data/total data: {}/{}\".format(valid_data_count, total_data_count)\n",
    "    avg_cost = 1.0*total_cost/total_data_count\n",
    "    print \"sum/count = {}/{}={}\".format(total_cost, total_data_count, avg_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ips_plus_estimator(pred_class_list, correct_class_list, logged_class_list, no_harvest):\n",
    "    total_classes = 10\n",
    "    count = 0\n",
    "    weights = 0\n",
    "    sum_ = 0\n",
    "    n = total_data_count = len(pred_class_list)\n",
    "    count = 0\n",
    "    count_p1 = 0\n",
    "    for i in range(n):\n",
    "        count += 1;\n",
    "        action_m = pred_class = pred_class_list[i]\n",
    "        correct_class = correct_class_list[i]\n",
    "        if pred_class == correct_class and pred_class != total_classes and not no_harvest:\n",
    "            # correct_class unknown\n",
    "            continue \n",
    "        if pred_class<correct_class:\n",
    "            cost = correct_class-pred_class+total_classes\n",
    "        else:\n",
    "            cost = pred_class-correct_class\n",
    "        #---- compute p ----\n",
    "        full_info_action = correct_class\n",
    "        a_logging_model = logged_class_list[i]\n",
    "        if a_logging_model > full_info_action:\n",
    "            count_p1 += 1\n",
    "            p = 1\n",
    "        else:\n",
    "            p = 0.2\n",
    "            #print \"count (a_logging_model {} <= full_info_action {}) is {}\".format(a_logging_model,full_info_action,count_p1)\n",
    "        #---- ---- ---- ----\n",
    "        sum_ += cost/p\n",
    "        weights += 1/p\n",
    "        #print \"[pred,target,cost]: [{},{},{}]\".format(pred_class, correct_class, cost)\n",
    "    print \"sum/count = {}/{}={}\".format(sum_, count, 1.0*sum_/count)\n",
    "    print \"sum/weights = {}/{}={}\".format(sum_, weights, 1.0*sum_/weights)\n",
    "    print \"p=1 for {}/{}\".format(count_p1, n)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy M_full===\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 9423/11856\n",
      "sum/count = 12654/11856=1.06730769231\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Data from deploying M_full                                            #\n",
    "#==========================================================================#\n",
    "\n",
    "print \"===Deploy M_full===\"\n",
    "dir_name = \"results-0522T0733-learning-1-5ms-deploy-full\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True) # pred_peak: prediction from learning model\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True) # upper_bound: actual allocation decision \"upper_bound = max(pred_peak, current_busy_cores+1)\" \n",
    "\n",
    "no_harvest = False\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy M_full===\n",
      "total valid data/total data: 10042/11855\n",
      "sum/count = 14719/11855=1.24158582876\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Data from deploying M_full                                            #\n",
    "#==========================================================================#\n",
    "\n",
    "print \"===Deploy M_full===\"\n",
    "dir_name = \"results-0605T1139-learning-1-5ms-deploy-full\"\n",
    "log_path = '160k-new/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True) # pred_peak: prediction from learning model\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True) # upper_bound: actual allocation decision \"upper_bound = max(pred_peak, current_busy_cores+1)\" \n",
    "primary_cores_list = df.primary_cores[1:].reset_index(drop=True)\n",
    "\n",
    "no_harvest = False\n",
    "#print \"\\nuse upper_bound_list:\"\n",
    "basic_estimator(primary_cores_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy shadow M_partial (ground truth) ===\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 11954/11954\n",
      "sum/count = 134812/11954=11.2775639953\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Data from deploying M_partial in shadow mode                             #\n",
    "#==========================================================================#\n",
    "\n",
    "print \"===Deploy shadow M_partial (ground truth) ===\"\n",
    "dir_name = \"results-0524T1645-learning-1-5ms-no-harvest-deploy-partial-max-capped\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True) # pred_peak: prediction from learning model\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True) # upper_bound: actual allocation decision \"upper_bound = max(pred_peak, current_busy_cores+1)\" \n",
    "\n",
    "no_harvest = True\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "basic_estimator(upper_bound_list, correct_class_list, no_harvest)\n",
    "\n",
    "\n",
    "folder = '160k-new'\n",
    "partial_output = {'window': df.iteration[1:].reset_index(drop=True),\n",
    "                    'pred_peak': pred_class_list,\n",
    "                    'upper_bound': upper_bound_list\n",
    "                    }\n",
    "partial_output_df = pd.DataFrame(partial_output, columns= ['window', 'pred_peak', 'upper_bound'])\n",
    "partial_output_df.to_csv(folder+\"/m_partial_biased_data_explore/160k_shadow_partial_output.csv\", index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy M_full (+explore)===\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 10385/11788\n",
      "sum/count = 17388/11788=1.47505938242\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Data from deploying M_full with 20% exploration                          #\n",
    "#==========================================================================#\n",
    "\n",
    "print \"===Deploy M_full (+explore)===\"\n",
    "dir_name = \"results-0524T1402-learning-1-5ms-deploy-full-explore\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True) # pred_peak: prediction from learning model\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True) # upper_bound: actual allocation decision \"upper_bound = max(pred_peak, current_busy_cores+1)\" \n",
    "\n",
    "no_harvest = False\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy M_full (+explore)===\n",
      "total valid data/total data: 11037/11777\n",
      "sum/count = 23405/11777=1.98734822111\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Data from deploying M_full with 20% exploration                          #\n",
    "#==========================================================================#\n",
    "\n",
    "print \"===Deploy M_full (+explore)===\"\n",
    "dir_name = \"results-0611T0925-learning-1-5ms-deploy-full-explore\"\n",
    "log_path = '160k-new/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True) # pred_peak: prediction from learning model\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True) # upper_bound: actual allocation decision \"upper_bound = max(pred_peak, current_busy_cores+1)\" \n",
    "primary_cores_list = df.primary_cores[1:].reset_index(drop=True)\n",
    "\n",
    "no_harvest = False\n",
    "#print \"\\nuse upper_bound_list:\"\n",
    "basic_estimator(primary_cores_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 11777\n",
      "total valid data: 10412\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-9-9d35c131abc1>, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-9d35c131abc1>\"\u001b[0;36m, line \u001b[0;32m46\u001b[0m\n\u001b[0;31m    return\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Evaluating M_partial on biased data from deploying M_full (+20% explore) #\n",
    "#==========================================================================#\n",
    "\n",
    "# 1. extract biased data from deploying M_full (+explore)\n",
    "dir_name = \"results-0611T0925-learning-1-5ms-deploy-full-explore\"\n",
    "folder = \"160k-new\"\n",
    "log_path = folder+'/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path) \n",
    "lines = []\n",
    "total_data_count = 0\n",
    "valid_data_count = 0\n",
    "logged_class_list = []\n",
    "correct_class_list = []\n",
    "current_busy_cpu_list = []\n",
    "for i in range(len(df.iteration)-1):\n",
    "    correct_class = df.cpu_max[i+1]\n",
    "    pred_class = df.pred_peak[i]\n",
    "    upper_bound = df.upper_bound[i]\n",
    "    current_busy_cpu = df.primary_busy_cores[i]\n",
    "    total_data_count += 1\n",
    "    if upper_bound > correct_class or upper_bound==10:\n",
    "        # overprediction\n",
    "        logged_class_list.append(max(pred_class, current_busy_cpu+1))\n",
    "        correct_class_list.append(correct_class)\n",
    "        current_busy_cpu_list.append(current_busy_cpu)\n",
    "\n",
    "        valid_data_count += 1\n",
    "        features = \"|busy_cores_prev_interval min:\"+str(df.f_min[i])+\" max:\"+str(df.f_max[i]) \\\n",
    "                    +\" avg:\"+str(df.f_avg[i])+\" stddev:\"+str(df.f_stddev[i]) \\\n",
    "                    +\" med:\"+str(df.f_med[i])\n",
    "        k = correct_class\n",
    "        if k<correct_class:\n",
    "            cost = correct_class-k+10\n",
    "        else:\n",
    "            cost = k-correct_class\n",
    "        label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "        sample = label+features\n",
    "        lines.append(sample)\n",
    "print \"total data: {}\\ntotal valid data: {}\".format(total_data_count, valid_data_count)\n",
    "outF = open(\"160k-new/m_partial_biased_data_explore/160k_data.txt\", \"w\")\n",
    "for line in lines:\n",
    "  # write line to output file\n",
    "  outF.write(line)\n",
    "  outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "# 2. (done in cmd line) use vw test M_partial on biased data and save its predictions \n",
    "\n",
    "\n",
    "# 3. read predictions from M_partial on biased data\n",
    "file = open(folder+\"/m_partial_biased_data_explore/160k_pred_prob.txt\", 'r') \n",
    "pred_prob_lines = file.readlines() \n",
    "pred_class_list = []\n",
    "upper_bound_list = []\n",
    "for i in range(len(pred_prob_lines)):\n",
    "    line = pred_prob_lines[i]\n",
    "    l = line.strip().split(' ')\n",
    "    for j in range(10):\n",
    "        if float(l[j])==1:\n",
    "            pred=j+1\n",
    "    upper_bound = pred\n",
    "    if i==0:\n",
    "        current_busy_cpu = current_busy_cpu_list[i]\n",
    "    else:\n",
    "        current_busy_cpu = min(current_busy_cpu_list[i], upper_bound_list[i-1])\n",
    "    upper_bound = max(pred, current_busy_cpu+1)\n",
    "    pred_class_list.append(pred)\n",
    "    upper_bound_list.append(upper_bound)\n",
    "    #print \"pred_class={}\\tupper_bound={}\\tcurrent_busy={}\\tcorrect_class{}\".format(pred, upper_bound,current_busy_cpu,correct_class_list[i])\n",
    "\n",
    "outF = open(folder+\"/m_partial_biased_data_explore/160k_pred.txt\", \"w\")\n",
    "for line in pred_class_list:\n",
    "    outF.write(str(line))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "outF = open(folder+\"/m_partial_biased_data_explore/160k_upper_bound.txt\", \"w\")\n",
    "for line in upper_bound_list:\n",
    "    outF.write(str(line))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "    \n",
    "# 4. run estimators\n",
    "print \"===Evaluating M_partial on biased data (+explore) ===\"\n",
    "no_harvest = True\n",
    "\n",
    "print \"\\n*basic estimator*\"\n",
    "print \"upper_bound_list\"\n",
    "basic_est = basic_estimator(upper_bound_list, correct_class_list, no_harvest)\n",
    "\n",
    "print \"\\n*ips+ estimator*\"\n",
    "print \"upper_bound_list\"\n",
    "ips_plus_est = ips_plus_estimator(upper_bound_list, correct_class_list, logged_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 11856\n",
      "total valid data: 9423\n",
      "===Evaluating M_partial on biased data ===\n",
      "\n",
      "*basic estimator*\n",
      "upper_bound_list\n",
      "total valid data/total data: 9423/9423\n",
      "sum/count = 99284/9423=10.5363472355\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Evaluating M_partial on biased data from deploying M_full                #\n",
    "#==========================================================================#\n",
    "\n",
    "# 1. extract biased data from deploying M_full\n",
    "dir_name = \"results-0522T0733-learning-1-5ms-deploy-full\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path) #biased data\n",
    "lines = []\n",
    "total_data_count = 0\n",
    "valid_data_count = 0\n",
    "logged_class_list = []\n",
    "correct_class_list = []\n",
    "current_busy_cpu_list = []\n",
    "for i in range(len(df.iteration)-1):\n",
    "    correct_class = df.cpu_max[i+1]\n",
    "    pred_class = df.pred_peak[i]\n",
    "    upper_bound = df.upper_bound[i]\n",
    "    current_busy_cpu = df.primary_busy_cores[i]\n",
    "    total_data_count += 1\n",
    "    if upper_bound > correct_class or upper_bound==10:\n",
    "        # overprediction\n",
    "        logged_class_list.append(max(pred_class, current_busy_cpu+1))\n",
    "        correct_class_list.append(correct_class)\n",
    "        current_busy_cpu_list.append(current_busy_cpu)\n",
    "        valid_data_count += 1\n",
    "        features = \"|busy_cores_prev_interval min:\"+str(df.f_min[i])+\" max:\"+str(df.f_max[i]) \\\n",
    "                    +\" avg:\"+str(df.f_avg[i])+\" stddev:\"+str(df.f_stddev[i]) \\\n",
    "                    +\" med:\"+str(df.f_med[i])\n",
    "        k = correct_class\n",
    "        if k<correct_class:\n",
    "            cost = correct_class-k+10\n",
    "        else:\n",
    "            cost = k-correct_class\n",
    "        label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "        sample = label+features\n",
    "        lines.append(sample)\n",
    "print \"total data: {}\\ntotal valid data: {}\".format(total_data_count, valid_data_count)\n",
    "outF = open(\"160k/m_partial_biased_data/160k_data.txt\", \"w\")\n",
    "for line in lines:\n",
    "  # write line to output file\n",
    "  outF.write(line)\n",
    "  outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "\n",
    "# 2. (done in cmd line) use vw test M_partial on biased data and save its predictions \n",
    "\n",
    "\n",
    "# 3. read predictions from M_partial on biased data\n",
    "file = open('160k/m_partial_biased_data/160k_pred_prob.txt', 'r') \n",
    "pred_prob_lines = file.readlines() \n",
    "pred_class_list = []\n",
    "upper_bound_list = []\n",
    "for i in range(len(pred_prob_lines)):\n",
    "    line = pred_prob_lines[i]\n",
    "    l = line.strip().split(' ')\n",
    "    for j in range(10):\n",
    "        if float(l[j])==1:\n",
    "            pred=j+1\n",
    "    upper_bound = pred\n",
    "    if i==0:\n",
    "        current_busy_cpu = current_busy_cpu_list[i]\n",
    "    else:\n",
    "        current_busy_cpu = min(current_busy_cpu_list[i], upper_bound_list[i-1])\n",
    "    upper_bound = max(pred, current_busy_cpu+1)\n",
    "    pred_class_list.append(pred)\n",
    "    upper_bound_list.append(upper_bound)\n",
    "    #print \"pred_class={}\\tupper_bound={}\\tcurrent_busy={}\\tcorrect_class{}\".format(pred, upper_bound,current_busy_cpu,correct_class_list[i])\n",
    "    \n",
    "outF = open(\"160k/m_partial_biased_data/160k_pred.txt\", \"w\")\n",
    "for line in pred_class_list:\n",
    "    outF.write(str(line))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "outF = open(\"160k/m_partial_biased_data/160k_upper_bound.txt\", \"w\")\n",
    "for line in upper_bound_list:\n",
    "    outF.write(str(line))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "\n",
    "# 4. run estimators\n",
    "print \"===Evaluating M_partial on biased data ===\"\n",
    "no_harvest = True\n",
    "\n",
    "print \"\\n*basic estimator*\"\n",
    "print \"upper_bound_list\"\n",
    "basic_est = basic_estimator(upper_bound_list, correct_class_list, no_harvest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "args1 = ['echo', '|busy_cores_prev_interval min:2 max:6 avg:3.5051550000000002 stddev:0.9857090000000001 med:4.0']\n",
    "args2 = ['nc', 'localhost', '26545']\n",
    "\n",
    "cmd1 = subprocess.Popen(args1, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "cmd2 = subprocess.Popen(args2, stdin=cmd1.stdout, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "stdout,stderr = cmd2.communicate()\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 11777\n",
      "total valid data: 11037\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Evaluating M_partial on biased data from deploying M_full (+20% explore) #\n",
    "#==========================================================================#\n",
    "import subprocess \n",
    "\n",
    "# 1. extract biased data from deploying M_full (+explore)\n",
    "dir_name = \"results-0611T0925-learning-1-5ms-deploy-full-explore\"\n",
    "folder = \"160k-new\"\n",
    "log_path = folder+'/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path) \n",
    "lines = []\n",
    "total_data_count = 0\n",
    "valid_data_count = 0\n",
    "logged_class_list = []\n",
    "correct_class_list = []\n",
    "current_busy_cpu_list = []\n",
    "valid_window_list = []\n",
    "for i in range(len(df.iteration)-1):\n",
    "    correct_class = df.cpu_max[i+1]\n",
    "    pred_class = df.pred_peak[i]\n",
    "    upper_bound = df.upper_bound[i]\n",
    "    primary_cpu = df.primary_cores[i+1]\n",
    "    #current_busy_cpu = df.primary_busy_cores[i]\n",
    "    total_data_count += 1\n",
    "    if primary_cpu > correct_class or primary_cpu ==10:\n",
    "        # overprediction\n",
    "        valid_window_list.append(i+1)\n",
    "        correct_class_list.append(correct_class)\n",
    "        logged_class_list.append(upper_bound)\n",
    "        valid_data_count += 1\n",
    "print \"total data: {}\\ntotal valid data: {}\".format(total_data_count, valid_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.61647186736\n",
      "17.0245537737\n",
      "25.5051191447\n",
      "34.0309866812\n",
      "42.5296729184\n",
      "50.9558756909\n",
      "76.2707257407\n",
      "84.8962580411\n",
      "93.4764881761\n"
     ]
    }
   ],
   "source": [
    "# 2. use vw test M_partial on biased data and save its predictions \n",
    "log_path = folder+'/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent_cpu.csv'\n",
    "df_cpu = pd.read_csv(log_path) \n",
    "clipped_window_list = []\n",
    "pred_peak_list = []\n",
    "upper_bound_list = []\n",
    "upper_bound = 10\n",
    "for i in valid_window_list:\n",
    "    s = df_cpu.loc[df_cpu['window'] == i].primary_busy_cores\n",
    "    #print current_busy_cpu\n",
    "    if s.max()==upper_bound and upper_bound!=10:\n",
    "        s = s.clip(upper=upper_bound)\n",
    "        #print \"window {} clipped\".format(i)\n",
    "        clipped_window_list.append(i)\n",
    "    current_busy_cpu = s.iloc[-1]\n",
    "    \n",
    "    features = \"|busy_cores_prev_interval min:\"+str(s.min())+\" max:\"+str(s.max()) \\\n",
    "                        +\" avg:\"+str(s.mean())+\" stddev:\"+str(s.std()) \\\n",
    "                        +\" med:\"+str(s.median())\n",
    "    args1 = ['echo', features]\n",
    "    args2 = ['nc', 'localhost', '26545']\n",
    "    cmd1 = subprocess.Popen(args1, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    cmd2 = subprocess.Popen(args2, stdin=cmd1.stdout, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    probs = cmd2.communicate()[0].strip().split(' ')\n",
    "    pred = probs.index('1.000000')+1\n",
    "    pred_peak_list.append(pred)\n",
    "    upper_bound = max(pred, current_busy_cpu+1)\n",
    "    upper_bound = min(upper_bound, 10)\n",
    "    upper_bound_list.append(upper_bound)\n",
    "    if i%1000==0:\n",
    "        print 100.0*len(upper_bound_list)/valid_data_count\n",
    "\n",
    "partial_output = {'window': valid_window_list,\n",
    "                    'pred_peak': pred_peak_list,\n",
    "                    'upper_bound': upper_bound_list\n",
    "                    }\n",
    "partial_output_df = pd.DataFrame(partial_output, columns= ['window', 'pred_peak', 'upper_bound'])\n",
    "partial_output_df.to_csv(folder+\"/m_partial_biased_data_explore/160k_partial_output.csv\", index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423 out of 11037 windows clipped\n",
      "11037\n"
     ]
    }
   ],
   "source": [
    "print \"{} out of {} windows clipped\".format(len(clipped_window_list), len(valid_window_list))\n",
    "print len(upper_bound_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound_list_explore = upper_bound_list\n",
    "correct_class_list_explore = correct_class_list\n",
    "logged_class_list_explore = logged_class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Evaluating M_partial on biased data (+explore) ===\n",
      "\n",
      "*basic estimator*\n",
      "upper_bound_list\n",
      "total valid data/total data: 11037/11037\n",
      "sum/count = 108600/11037=9.83963033433\n",
      "\n",
      "*ips+ estimator*\n",
      "upper_bound_list\n",
      "sum/count = 174372.0/11037=15.7988583854\n",
      "sum/weights = 174372.0/16313.0=10.6891436278\n",
      "p=1 for 9718/11037\n"
     ]
    }
   ],
   "source": [
    "# 3. run estimators\n",
    "print \"===Evaluating M_partial on biased data (+explore) ===\"\n",
    "no_harvest = True\n",
    "\n",
    "print \"\\n*basic estimator*\"\n",
    "print \"upper_bound_list\"\n",
    "basic_est = basic_estimator(upper_bound_list_explore, correct_class_list_explore, no_harvest)\n",
    "\n",
    "print \"\\n*ips+ estimator*\"\n",
    "print \"upper_bound_list\"\n",
    "ips_plus_est = ips_plus_estimator(upper_bound_list_explore, correct_class_list_explore, logged_class_list_explore, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 11855\n",
      "total valid data: 10042\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Evaluating M_partial on biased data from deploying M_full #\n",
    "#==========================================================================#\n",
    "import subprocess \n",
    "\n",
    "# 1. extract biased data from deploying M_full \n",
    "dir_name = \"results-0605T1139-learning-1-5ms-deploy-full\"\n",
    "folder = \"160k-new\"\n",
    "log_path = folder+'/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path) \n",
    "lines = []\n",
    "total_data_count = 0\n",
    "valid_data_count = 0\n",
    "logged_class_list = []\n",
    "correct_class_list = []\n",
    "current_busy_cpu_list = []\n",
    "valid_window_list = []\n",
    "for i in range(len(df.window)-1):\n",
    "    correct_class = df.cpu_max[i+1]\n",
    "    pred_class = df.pred_peak[i]\n",
    "    upper_bound = df.upper_bound[i]\n",
    "    primary_cpu = df.primary_cores[i+1]\n",
    "    #current_busy_cpu = df.primary_busy_cores[i]\n",
    "    total_data_count += 1\n",
    "    if primary_cpu > correct_class or primary_cpu ==10:\n",
    "        # overprediction\n",
    "        valid_window_list.append(i+1)\n",
    "        correct_class_list.append(correct_class)\n",
    "        logged_class_list.append(upper_bound)\n",
    "        valid_data_count += 1\n",
    "print \"total data: {}\\ntotal valid data: {}\".format(total_data_count, valid_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.71340370444\n",
      "25.6024696276\n",
      "42.3819956184\n",
      "50.9659430392\n",
      "67.8749253137\n",
      "76.1003784107\n",
      "84.405496913\n",
      "92.7703644692\n"
     ]
    }
   ],
   "source": [
    "# 2. use vw test M_partial on biased data and save its predictions \n",
    "log_path = folder+'/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent_cpu.csv'\n",
    "df_cpu = pd.read_csv(log_path) \n",
    "clipped_window_list = []\n",
    "pred_peak_list = []\n",
    "upper_bound_list = []\n",
    "upper_bound = 10\n",
    "for i in valid_window_list:\n",
    "    s = df_cpu.loc[df_cpu['window'] == i].primary_busy_cores\n",
    "    #print current_busy_cpu\n",
    "    if s.max()==upper_bound and upper_bound!=10:\n",
    "        s = s.clip(upper=upper_bound)\n",
    "        #print \"window {} clipped\".format(i)\n",
    "        clipped_window_list.append(i)\n",
    "    current_busy_cpu = s.iloc[-1]\n",
    "    \n",
    "    features = \"|busy_cores_prev_interval min:\"+str(s.min())+\" max:\"+str(s.max()) \\\n",
    "                        +\" avg:\"+str(s.mean())+\" stddev:\"+str(s.std()) \\\n",
    "                        +\" med:\"+str(s.median())\n",
    "    args1 = ['echo', features]\n",
    "    args2 = ['nc', 'localhost', '26545']\n",
    "    cmd1 = subprocess.Popen(args1, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    cmd2 = subprocess.Popen(args2, stdin=cmd1.stdout, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    probs = cmd2.communicate()[0].strip().split(' ')\n",
    "    pred = probs.index('1.000000')+1\n",
    "    pred_peak_list.append(pred)\n",
    "    upper_bound = max(pred, current_busy_cpu+1)\n",
    "    upper_bound = min(upper_bound, 10)\n",
    "    upper_bound_list.append(upper_bound)\n",
    "    if i%1000==0:\n",
    "        print 100.0*len(upper_bound_list)/valid_data_count\n",
    "\n",
    "partial_output = {'window': valid_window_list,\n",
    "                    'pred_peak': pred_peak_list,\n",
    "                    'upper_bound': upper_bound_list\n",
    "                    }\n",
    "partial_output_df = pd.DataFrame(partial_output, columns= ['window', 'pred_peak', 'upper_bound'])\n",
    "partial_output_df.to_csv(folder+\"/m_partial_biased_data/160k_partial_output.csv\", index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1182 out of 10042 windows clipped\n",
      "10042\n"
     ]
    }
   ],
   "source": [
    "print \"{} out of {} windows clipped\".format(len(clipped_window_list), len(valid_window_list))\n",
    "print len(upper_bound_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Evaluating M_partial on biased data ===\n",
      "\n",
      "*basic estimator*\n",
      "upper_bound_list\n",
      "total valid data/total data: 10042/10042\n",
      "sum/count = 97725/10042=9.7316271659\n"
     ]
    }
   ],
   "source": [
    "# 3. run estimators\n",
    "print \"===Evaluating M_partial on biased data ===\"\n",
    "no_harvest = True\n",
    "\n",
    "print \"\\n*basic estimator*\"\n",
    "print \"upper_bound_list\"\n",
    "basic_est = basic_estimator(upper_bound_list, correct_class_list, no_harvest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
