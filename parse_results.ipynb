{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_estimator(pred_class_list, correct_class_list, no_harvest):\n",
    "    total_classes = 10\n",
    "    total_cost = 0\n",
    "    total_data_count = len(pred_class_list)\n",
    "    valid_data_count = 0\n",
    "    for i in range(total_data_count):\n",
    "        pred_class = pred_class_list[i]\n",
    "        correct_class = correct_class_list[i]\n",
    "        if pred_class > correct_class or pred_class == 10 or no_harvest:\n",
    "            if pred_class<correct_class:\n",
    "                cost = correct_class-pred_class+total_classes\n",
    "            else:\n",
    "                cost = pred_class-correct_class\n",
    "            total_cost += cost\n",
    "            valid_data_count += 1\n",
    "            #print \"[pred,target,cost]: [{},{},{}]\".format(pred_class, correct_class, cost)\n",
    "    print \"total valid data/total data: {}/{}\".format(valid_data_count, total_data_count)\n",
    "    avg_cost = 1.0*total_cost/total_data_count\n",
    "    print \"sum/count = {}/{}={}\".format(total_cost, total_data_count, avg_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ips_plus_estimator(pred_class_list, correct_class_list, logged_class_list, no_harvest, use_logged_action):\n",
    "    total_classes = 10\n",
    "    count = 0\n",
    "    weights = 0\n",
    "    sum_ = 0\n",
    "    n = total_data_count = len(pred_class_list)\n",
    "    count = 0\n",
    "    count_p1 = 0\n",
    "    for i in range(n):\n",
    "        count += 1;\n",
    "        action_m = pred_class = pred_class_list[i]\n",
    "        correct_class = correct_class_list[i]\n",
    "        if pred_class == correct_class and pred_class != total_classes and not no_harvest:\n",
    "            # correct_class unknown\n",
    "            continue \n",
    "        if pred_class<correct_class:\n",
    "            cost = correct_class-pred_class+total_classes\n",
    "        else:\n",
    "            cost = pred_class-correct_class\n",
    "        #---- compute p ----\n",
    "        full_info_action = correct_class\n",
    "        if use_logged_action:\n",
    "            a_logging_model = logged_class_list[i]\n",
    "            if a_logging_model > full_info_action:\n",
    "                count_p1 += 1\n",
    "                p = 1\n",
    "                #print \"count (a_logging_model {} > full_info_action {}) is {}\".format(a_logging_model,full_info_action,count_p1)\n",
    "            else:\n",
    "                p = 0.2\n",
    "        else:\n",
    "            if action_m > full_info_action:\n",
    "                count_p1 += 1\n",
    "                p = 1\n",
    "                #print \"count (action_m {} > full_info_action {}) is {}\".format(action_m,full_info_action,count_p1)\n",
    "            else:\n",
    "                p = 0.2\n",
    "        #---- ---- ---- ----\n",
    "        sum_ += cost/p\n",
    "        weights += 1/p\n",
    "        #print \"[pred,target,cost]: [{},{},{}]\".format(pred_class, correct_class, cost)\n",
    "    print \"sum/count = {}/{}={}\".format(sum_, count, sum_/count)\n",
    "    print \"sum/weights = {}/{}={}\".format(sum_, weights, sum_/weights)\n",
    "    print \"p=1 for {}/{}\".format(count_p1, n)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy M_full===\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 9423/11856\n",
      "sum/count = 12654/11856=1.06730769231\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Data from deploying M_full                                            #\n",
    "#==========================================================================#\n",
    "\n",
    "print \"===Deploy M_full===\"\n",
    "dir_name = \"results-0522T0733-learning-1-5ms-deploy-full\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True) # pred_peak: prediction from learning model\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True) # upper_bound: actual allocation decision \"upper_bound = max(pred_peak, current_busy_cores+1)\" \n",
    "\n",
    "no_harvest = False\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy shadow M_partial (ground truth) ===\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 11954/11954\n",
      "sum/count = 134812/11954=11.2775639953\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Data from deploying M_partial in shadow mode                             #\n",
    "#==========================================================================#\n",
    "\n",
    "print \"===Deploy shadow M_partial (ground truth) ===\"\n",
    "dir_name = \"results-0524T1645-learning-1-5ms-no-harvest-deploy-partial-max-capped\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True) # pred_peak: prediction from learning model\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True) # upper_bound: actual allocation decision \"upper_bound = max(pred_peak, current_busy_cores+1)\" \n",
    "\n",
    "no_harvest = True\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy M_full (+explore)===\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 10385/11788\n",
      "sum/count = 17388/11788=1.47505938242\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Data from deploying M_full with 20% exploration                          #\n",
    "#==========================================================================#\n",
    "\n",
    "print \"===Deploy M_full (+explore)===\"\n",
    "dir_name = \"results-0524T1402-learning-1-5ms-deploy-full-explore\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True) # pred_peak: prediction from learning model\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True) # upper_bound: actual allocation decision \"upper_bound = max(pred_peak, current_busy_cores+1)\" \n",
    "\n",
    "no_harvest = False\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 11788\n",
      "total valid data: 10385\n",
      "===Evaluating M_partial on biased data (+explore) ===\n",
      "\n",
      "*basic estimator*\n",
      "upper_bound_list\n",
      "total valid data/total data: 10385/10385\n",
      "sum/count = 103061/10385=9.92402503611\n",
      "\n",
      "*ips+ estimator*\n",
      "upper_bound_list\n",
      "sum/count = 514713.0/10385=49.5631198844\n",
      "sum/weights = 514713.0/51349.0=10.0238174064\n",
      "p=1 for 144/10385\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Evaluating M_partial on biased data from deploying M_full (+20% explore) #\n",
    "#==========================================================================#\n",
    "\n",
    "# 1. extract biased data from deploying M_full (+explore)\n",
    "dir_name = \"results-0524T1402-learning-1-5ms-deploy-full-explore\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path) \n",
    "lines = []\n",
    "total_data_count = 0\n",
    "valid_data_count = 0\n",
    "logged_class_list = []\n",
    "correct_class_list = []\n",
    "current_busy_cpu_list = []\n",
    "for i in range(len(df.iteration)-1):\n",
    "    correct_class = df.cpu_max[i+1]\n",
    "    pred_class = df.pred_peak[i]\n",
    "    upper_bound = df.upper_bound[i]\n",
    "    current_busy_cpu = df.primary_busy_cores[i]\n",
    "    total_data_count += 1\n",
    "    if upper_bound > correct_class or upper_bound==10:\n",
    "        # overprediction\n",
    "        logged_class_list.append(max(pred_class, current_busy_cpu+1))\n",
    "        correct_class_list.append(correct_class)\n",
    "        current_busy_cpu_list.append(current_busy_cpu)\n",
    "\n",
    "        valid_data_count += 1\n",
    "        features = \"|busy_cores_prev_interval min:\"+str(df.f_min[i])+\" max:\"+str(df.f_max[i]) \\\n",
    "                    +\" avg:\"+str(df.f_avg[i])+\" stddev:\"+str(df.f_stddev[i]) \\\n",
    "                    +\" med:\"+str(df.f_med[i])\n",
    "        k = correct_class\n",
    "        if k<correct_class:\n",
    "            cost = correct_class-k+10\n",
    "        else:\n",
    "            cost = k-correct_class\n",
    "        label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "        sample = label+features\n",
    "        lines.append(sample)\n",
    "print \"total data: {}\\ntotal valid data: {}\".format(total_data_count, valid_data_count)\n",
    "outF = open(\"160k/m_partial_biased_data_explore/160k_data.txt\", \"w\")\n",
    "for line in lines:\n",
    "  # write line to output file\n",
    "  outF.write(line)\n",
    "  outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "\n",
    "# 2. (done in cmd line) use vw test M_partial on biased data and save its predictions \n",
    "\n",
    "\n",
    "# 3. read predictions from M_partial on biased data\n",
    "file = open(\"160k/m_partial_biased_data_explore/160k_pred_prob.txt\", 'r') \n",
    "pred_prob_lines = file.readlines() \n",
    "pred_class_list = []\n",
    "upper_bound_list = []\n",
    "for i in range(len(pred_prob_lines)):\n",
    "    line = pred_prob_lines[i]\n",
    "    l = line.strip().split(' ')\n",
    "    for j in range(10):\n",
    "        if float(l[j])==1:\n",
    "            pred=j+1\n",
    "    upper_bound = pred\n",
    "    if i==0:\n",
    "        current_busy_cpu = current_busy_cpu_list[i]\n",
    "    else:\n",
    "        current_busy_cpu = min(current_busy_cpu_list[i], upper_bound_list[i-1])\n",
    "    upper_bound = max(pred, current_busy_cpu+1)\n",
    "    pred_class_list.append(pred)\n",
    "    upper_bound_list.append(upper_bound)\n",
    "    #print \"pred_class={}\\tupper_bound={}\\tcurrent_busy={}\\tcorrect_class{}\".format(pred, upper_bound,current_busy_cpu,correct_class_list[i])\n",
    "\n",
    "outF = open(\"160k/m_partial_biased_data_explore/160k_pred.txt\", \"w\")\n",
    "for line in pred_class_list:\n",
    "    outF.write(str(line))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "outF = open(\"160k/m_partial_biased_data_explore/160k_upper_bound.txt\", \"w\")\n",
    "for line in upper_bound_list:\n",
    "    outF.write(str(line))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "    \n",
    "# 4. run estimators\n",
    "print \"===Evaluating M_partial on biased data (+explore) ===\"\n",
    "no_harvest = True\n",
    "\n",
    "print \"\\n*basic estimator*\"\n",
    "print \"upper_bound_list\"\n",
    "basic_est = basic_estimator(upper_bound_list, correct_class_list, no_harvest)\n",
    "\n",
    "print \"\\n*ips+ estimator*\"\n",
    "print \"upper_bound_list\"\n",
    "ips_plus_est = ips_plus_estimator(upper_bound_list, correct_class_list, logged_class_list, no_harvest, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 11856\n",
      "total valid data: 9423\n",
      "===Evaluating M_partial on biased data ===\n",
      "\n",
      "*basic estimator*\n",
      "upper_bound_list\n",
      "total valid data/total data: 9423/9423\n",
      "sum/count = 99284/9423=10.5363472355\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================#\n",
    "# Evaluating M_partial on biased data from deploying M_full                #\n",
    "#==========================================================================#\n",
    "\n",
    "# 1. extract biased data from deploying M_full\n",
    "dir_name = \"results-0522T0733-learning-1-5ms-deploy-full\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path) #biased data\n",
    "lines = []\n",
    "total_data_count = 0\n",
    "valid_data_count = 0\n",
    "logged_class_list = []\n",
    "correct_class_list = []\n",
    "current_busy_cpu_list = []\n",
    "for i in range(len(df.iteration)-1):\n",
    "    correct_class = df.cpu_max[i+1]\n",
    "    pred_class = df.pred_peak[i]\n",
    "    upper_bound = df.upper_bound[i]\n",
    "    current_busy_cpu = df.primary_busy_cores[i]\n",
    "    total_data_count += 1\n",
    "    if upper_bound > correct_class or upper_bound==10:\n",
    "        # overprediction\n",
    "        logged_class_list.append(max(pred_class, current_busy_cpu+1))\n",
    "        correct_class_list.append(correct_class)\n",
    "        current_busy_cpu_list.append(current_busy_cpu)\n",
    "        valid_data_count += 1\n",
    "        features = \"|busy_cores_prev_interval min:\"+str(df.f_min[i])+\" max:\"+str(df.f_max[i]) \\\n",
    "                    +\" avg:\"+str(df.f_avg[i])+\" stddev:\"+str(df.f_stddev[i]) \\\n",
    "                    +\" med:\"+str(df.f_med[i])\n",
    "        k = correct_class\n",
    "        if k<correct_class:\n",
    "            cost = correct_class-k+10\n",
    "        else:\n",
    "            cost = k-correct_class\n",
    "        label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "        sample = label+features\n",
    "        lines.append(sample)\n",
    "print \"total data: {}\\ntotal valid data: {}\".format(total_data_count, valid_data_count)\n",
    "outF = open(\"160k/m_partial_biased_data/160k_data.txt\", \"w\")\n",
    "for line in lines:\n",
    "  # write line to output file\n",
    "  outF.write(line)\n",
    "  outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "\n",
    "# 2. (done in cmd line) use vw test M_partial on biased data and save its predictions \n",
    "\n",
    "\n",
    "# 3. read predictions from M_partial on biased data\n",
    "file = open('160k/m_partial_biased_data/160k_pred_prob.txt', 'r') \n",
    "pred_prob_lines = file.readlines() \n",
    "pred_class_list = []\n",
    "upper_bound_list = []\n",
    "for i in range(len(pred_prob_lines)):\n",
    "    line = pred_prob_lines[i]\n",
    "    l = line.strip().split(' ')\n",
    "    for j in range(10):\n",
    "        if float(l[j])==1:\n",
    "            pred=j+1\n",
    "    upper_bound = pred\n",
    "    if i==0:\n",
    "        current_busy_cpu = current_busy_cpu_list[i]\n",
    "    else:\n",
    "        current_busy_cpu = min(current_busy_cpu_list[i], upper_bound_list[i-1])\n",
    "    upper_bound = max(pred, current_busy_cpu+1)\n",
    "    pred_class_list.append(pred)\n",
    "    upper_bound_list.append(upper_bound)\n",
    "    #print \"pred_class={}\\tupper_bound={}\\tcurrent_busy={}\\tcorrect_class{}\".format(pred, upper_bound,current_busy_cpu,correct_class_list[i])\n",
    "    \n",
    "outF = open(\"160k/m_partial_biased_data/160k_pred.txt\", \"w\")\n",
    "for line in pred_class_list:\n",
    "    outF.write(str(line))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "outF = open(\"160k/m_partial_biased_data/160k_upper_bound.txt\", \"w\")\n",
    "for line in upper_bound_list:\n",
    "    outF.write(str(line))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "\n",
    "# 4. run estimators\n",
    "print \"===Evaluating M_partial on biased data ===\"\n",
    "no_harvest = True\n",
    "\n",
    "print \"\\n*basic estimator*\"\n",
    "print \"upper_bound_list\"\n",
    "basic_est = basic_estimator(upper_bound_list, correct_class_list, no_harvest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
