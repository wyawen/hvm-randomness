{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_estimator(pred_class_list, correct_class_list, no_harvest):\n",
    "    total_classes = 10\n",
    "    total_cost = 0\n",
    "    total_data_count = len(pred_class_list)\n",
    "    valid_data_count = 0\n",
    "    for i in range(total_data_count):\n",
    "        pred_class = pred_class_list[i]\n",
    "        correct_class = correct_class_list[i]\n",
    "        if pred_class > correct_class or pred_class == 10 or no_harvest:\n",
    "            if pred_class<correct_class:\n",
    "                cost = correct_class-pred_class+total_classes\n",
    "            else:\n",
    "                cost = pred_class-correct_class\n",
    "            total_cost += cost\n",
    "            valid_data_count += 1\n",
    "            #print \"[pred,target,cost]: [{},{},{}]\".format(pred_class, correct_class, cost)\n",
    "    print \"total valid data/total data: {}/{}\".format(valid_data_count, total_data_count)\n",
    "    avg_cost = 1.0*total_cost/total_data_count\n",
    "    print \"sum/count = {}/{}={}\".format(total_cost, total_data_count, avg_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy M_full===\n",
      "\n",
      "use pred_class_list:\n",
      "total valid data/total data: 9408/11856\n",
      "sum/count = 12619/11856=1.06435560054\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 9423/11856\n",
      "sum/count = 12654/11856=1.06730769231\n"
     ]
    }
   ],
   "source": [
    "print \"===Deploy M_full===\"\n",
    "dir_name = \"results-0522T0733-learning-1-5ms-deploy-full\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True)\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True)\n",
    "\n",
    "no_harvest = False\n",
    "print \"\\nuse pred_class_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy M_partial===\n",
      "\n",
      "use pred_class_list:\n",
      "total valid data/total data: 204/11896\n",
      "sum/count = 204/11896=0.0171486213853\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 349/11896\n",
      "sum/count = 352/11896=0.0295897780767\n"
     ]
    }
   ],
   "source": [
    "print \"===Deploy M_partial===\"\n",
    "dir_name = \"results-0522T0737-learning-1-5ms-deploy-partial\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True)\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True)\n",
    "\n",
    "no_harvest = False\n",
    "print \"\\nuse pred_class_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy shadow M_partial===\n",
      "\n",
      "use pred_class_list:\n",
      "total valid data/total data: 0/11954\n",
      "sum/count = 0/11954=0.0\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 38/11954\n",
      "sum/count = 40/11954=0.00334616028108\n"
     ]
    }
   ],
   "source": [
    "print \"===Deploy shadow M_partial===\"\n",
    "dir_name = \"results-0524T1645-learning-1-5ms-no-harvest-deploy-partial-no-pred-max-capped\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True)\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True)\n",
    "\n",
    "no_harvest = True\n",
    "print \"\\nuse pred_class_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy shadow M_partial===\n",
      "logged_upper_bound 10 != upper_bound 4\n",
      "\n",
      "use pred_class_list:\n",
      "total valid data/total data: 11954/11954\n",
      "sum/count = 148256/11954=12.4022084658\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 11954/11954\n",
      "sum/count = 134822/11954=11.2784005354\n"
     ]
    }
   ],
   "source": [
    "print \"===Deploy shadow M_partial===\"\n",
    "dir_name = \"results-0524T1645-learning-1-5ms-no-harvest-deploy-partial-no-pred-max-capped\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = []\n",
    "pred_class_list = []\n",
    "upper_bound_list = []\n",
    "for i in range(len(df.iteration)-1):\n",
    "    correct_class = df.cpu_max[i+1]\n",
    "    pred_class = df.pred_peak[i]\n",
    "    logged_upper_bound = df.upper_bound[i]\n",
    "    if i==0:\n",
    "        current_busy_cpu = df.primary_busy_cores[i]\n",
    "    else:\n",
    "        current_busy_cpu = min(df.primary_busy_cores[i], upper_bound_list[i-1])\n",
    "    upper_bound = max(pred, current_busy_cpu+1)\n",
    "    upper_bound_list.append(upper_bound)\n",
    "    correct_class_list.append(correct_class)\n",
    "    pred_class_list.append(pred_class)\n",
    "    if logged_upper_bound != upper_bound:\n",
    "        print \"logged_upper_bound {} != upper_bound {}\".format(logged_upper_bound, upper_bound)\n",
    "\n",
    "no_harvest = True\n",
    "print \"\\nuse pred_class_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy shadow M_partial===\n",
      "\n",
      "use pred_class_list:\n",
      "total valid data/total data: 11950/11950\n",
      "sum/count = 147840/11950=12.3715481172\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 11950/11950\n",
      "sum/count = 134589/11950=11.2626778243\n"
     ]
    }
   ],
   "source": [
    "print \"===Deploy shadow M_partial===\"\n",
    "dir_name = \"results-0524T1723-learning-1-5ms-no-harvest-deploy-partial-no-pred-max-capped-3iter\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True)\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True)\n",
    "\n",
    "no_harvest = True\n",
    "print \"\\nuse pred_class_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy M_full (+explore)===\n",
      "-------- iter 0 --------\n",
      "\n",
      "use pred_class_list:\n",
      "total valid data/total data: 11950/11950\n",
      "sum/count = 147840/11950=12.3715481172\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 11950/11950\n",
      "sum/count = 134589/11950=11.2626778243\n",
      "-------- iter 1 --------\n",
      "\n",
      "use pred_class_list:\n",
      "total valid data/total data: 11946/11946\n",
      "sum/count = 148145/11946=12.4012221664\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 11946/11946\n",
      "sum/count = 134988/11946=11.2998493219\n",
      "-------- iter 2 --------\n",
      "\n",
      "use pred_class_list:\n",
      "total valid data/total data: 11948/11948\n",
      "sum/count = 148106/11948=12.395882156\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 11948/11948\n",
      "sum/count = 134508/11948=11.2577837295\n"
     ]
    }
   ],
   "source": [
    "print \"===Deploy M_full (+explore)===\"\n",
    "dir_name = \"results-0524T1723-learning-1-5ms-no-harvest-deploy-partial-no-pred-max-capped-3iter\"\n",
    "\n",
    "for i in range(3):\n",
    "    print \"-------- iter {} --------\".format(i)\n",
    "    log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/'+str(i)+'/hvmagent.csv'\n",
    "    df = pd.read_csv(log_path)\n",
    "\n",
    "    correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "    pred_class_list = df.pred_peak[:-1].reset_index(drop=True)\n",
    "    upper_bound_list = df.upper_bound[:-1].reset_index(drop=True)\n",
    "\n",
    "    no_harvest = True\n",
    "    print \"\\nuse pred_class_list:\"\n",
    "    avg_cost_eval_actual_run = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "\n",
    "    print \"\\nuse upper_bound_list:\"\n",
    "    avg_cost_eval_actual_run = basic_estimator(upper_bound_list, correct_class_list, no_harvest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy M_partial (+explore)===\n",
      "\n",
      "use pred_class_list:\n",
      "total valid data/total data: 2730/11845\n",
      "sum/count = 8605/11845=0.726466863656\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 3432/11845\n",
      "sum/count = 9364/11845=0.790544533558\n"
     ]
    }
   ],
   "source": [
    "print \"===Deploy M_partial (+explore)===\"\n",
    "dir_name = \"results-0522T0822-learning-1-5ms-deploy-partial-explore\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True)\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True)\n",
    "\n",
    "no_harvest = False\n",
    "print \"\\nuse pred_class_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Deploy shadow M_partial (+explore)===\n",
      "\n",
      "use pred_class_list:\n",
      "total valid data/total data: 11955/11955\n",
      "sum/count = 56874/11955=4.75734002509\n",
      "\n",
      "use upper_bound_list:\n",
      "total valid data/total data: 11955/11955\n",
      "sum/count = 8533/11955=0.713759933082\n"
     ]
    }
   ],
   "source": [
    "print \"===Deploy shadow M_partial (+explore)===\"\n",
    "dir_name = \"results-0522T0824-learning-1-5ms-no-harvest-deploy-partial-no-pred-max-capped-explore\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "correct_class_list = df.cpu_max[1:].reset_index(drop=True)\n",
    "pred_class_list = df.pred_peak[:-1].reset_index(drop=True)\n",
    "upper_bound_list = df.upper_bound[:-1].reset_index(drop=True)\n",
    "\n",
    "no_harvest = True\n",
    "print \"\\nuse pred_class_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "\n",
    "print \"\\nuse upper_bound_list:\"\n",
    "avg_cost_eval_actual_run = basic_estimator(upper_bound_list, correct_class_list, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Evaluating M_partial on biased data ===\n",
      "total valid data/total data: 9408/9408\n",
      "avg cost: 11.9345238095\n"
     ]
    }
   ],
   "source": [
    "print \"===Evaluating M_partial on biased data ===\"\n",
    "no_harvest = True\n",
    "avg_cost_eval_actual_run = basic_estimator(pred_class_lines, correct_class_lines, no_harvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 11791\n",
      "total valid data: 10362\n",
      "total data: 11789\n",
      "total valid data: 10455\n",
      "total data: 11789\n",
      "total valid data: 10518\n"
     ]
    }
   ],
   "source": [
    "# extract biased data from explore\n",
    "dir_name = \"results-0524T1732-learning-1-5ms-deploy-full-explore-3iter\"\n",
    "for index in range(3):\n",
    "    log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/'+str(index)+'/hvmagent.csv'\n",
    "    df = pd.read_csv(log_path) #biased data\n",
    "    lines = []\n",
    "    total_data_count = 0\n",
    "    valid_data_count = 0\n",
    "    logged_class_list = []\n",
    "    correct_class_list = []\n",
    "    current_busy_cpu_list = []\n",
    "    for i in range(len(df.iteration)-1):\n",
    "        correct_class = df.cpu_max[i+1]\n",
    "        pred_class = df.pred_peak[i]\n",
    "        upper_bound = df.upper_bound[i]\n",
    "        current_busy_cpu = df.primary_busy_cores[i]\n",
    "        total_data_count += 1\n",
    "        if upper_bound > correct_class or upper_bound==10:\n",
    "            # overprediction\n",
    "            logged_class_list.append(max(pred_class, current_busy_cpu+1))\n",
    "            correct_class_list.append(correct_class)\n",
    "            current_busy_cpu_list.append(current_busy_cpu)\n",
    "\n",
    "            valid_data_count += 1\n",
    "            features = \"|busy_cores_prev_interval min:\"+str(df.f_min[i])+\" max:\"+str(df.f_max[i]) \\\n",
    "                        +\" avg:\"+str(df.f_avg[i])+\" stddev:\"+str(df.f_stddev[i]) \\\n",
    "                        +\" med:\"+str(df.f_med[i])\n",
    "            #lines.append(features)\n",
    "            '''\n",
    "            for k in range(1,11):\n",
    "                if k<correct_class:\n",
    "                    cost = correct_class-k+10\n",
    "                else:\n",
    "                    cost = k-correct_class\n",
    "                label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "                sample = label+features\n",
    "                lines.append(sample)\n",
    "            '''\n",
    "            k = correct_class\n",
    "            if k<correct_class:\n",
    "                cost = correct_class-k+10\n",
    "            else:\n",
    "                cost = k-correct_class\n",
    "            label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "            sample = label+features\n",
    "            lines.append(sample)\n",
    "\n",
    "    print \"total data: {}\\ntotal valid data: {}\".format(total_data_count, valid_data_count)\n",
    "\n",
    "    outF = open(\"160k/m_partial_biased_data_explore_3iter/\"+str(index)+\"/160k_data.txt\", \"w\")\n",
    "    for line in lines:\n",
    "      # write line to output file\n",
    "      outF.write(line)\n",
    "      outF.write(\"\\n\")\n",
    "    outF.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(3):\n",
    "    # evaluate m_partial on biased data\n",
    "    file = open(\"160k/m_partial_biased_data_explore_3iter/\"+str(index)+\"/160k_pred_prob.txt\", 'r') \n",
    "    pred_prob_lines = file.readlines() \n",
    "    pred_class_list = []\n",
    "    upper_bound_list = []\n",
    "    for i in range(len(pred_prob_lines)):\n",
    "        line = pred_prob_lines[i]\n",
    "        l = line.strip().split(' ')\n",
    "        for j in range(10):\n",
    "            if float(l[j])==1:\n",
    "                pred=j+1\n",
    "        upper_bound = pred\n",
    "        if i==0:\n",
    "            current_busy_cpu = current_busy_cpu_list[i]\n",
    "        else:\n",
    "            current_busy_cpu = min(current_busy_cpu_list[i], upper_bound_list[i-1])\n",
    "            #current_busy_cpu = current_busy_cpu_list[i]\n",
    "        upper_bound = max(pred, current_busy_cpu+1)\n",
    "        pred_class_list.append(pred)\n",
    "        upper_bound_list.append(upper_bound)\n",
    "        #print \"pred_class={}\\tupper_bound={}\\tcurrent_busy={}\\tcorrect_class{}\".format(pred, upper_bound,current_busy_cpu,correct_class_list[i])\n",
    "\n",
    "    outF = open(\"160k/m_partial_biased_data_explore_3iter/\"+str(index)+\"/160k_pred.txt\", \"w\")\n",
    "    for line in pred_class_list:\n",
    "        # write line to output file\n",
    "        #print line\n",
    "        outF.write(str(line))\n",
    "        outF.write(\"\\n\")\n",
    "    outF.close()\n",
    "\n",
    "    outF = open(\"160k/m_partial_biased_data_explore_3iter/\"+str(index)+\"/160k_upper_bound.txt\", \"w\")\n",
    "    for line in upper_bound_list:\n",
    "        # write line to output file\n",
    "        #print line\n",
    "        outF.write(str(line))\n",
    "        outF.write(\"\\n\")\n",
    "    outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 11791\n",
      "total valid data: 10362\n",
      "10362\n",
      "10362\n",
      "10362\n",
      "===Evaluating M_partial on biased data ===\n",
      "\n",
      "*basic estimator*\n",
      "pred_class_list\n",
      "total valid data/total data: 10362/10362\n",
      "sum/count = 121079/10362=11.6849063887\n",
      "upper_bound_list\n",
      "total valid data/total data: 10362/10362\n",
      "sum/count = 102954/10362=9.93572669369\n",
      "\n",
      "*ips+ estimator*\n",
      "pred_class_list\n",
      "sum/count = 121127.0/10362=11.6895386991\n",
      "sum/weights = 121127.0/10366.0=11.6850279761\n",
      "p=1 for 10361/10362\n",
      "upper_bound_list\n",
      "sum/count = 103002.0/10362=9.94035900405\n",
      "sum/weights = 103002.0/10366.0=9.93652324908\n",
      "p=1 for 10361/10362\n",
      "\n",
      "pred_class_list\n",
      "sum/count = 605395.0/10362=58.4245319436\n",
      "sum/weights = 605395.0/51810.0=11.6849063887\n",
      "p=1 for 0/10362\n",
      "upper_bound_list\n",
      "sum/count = 514242.0/10362=49.6276780544\n",
      "sum/weights = 514242.0/51298.0=10.024601349\n",
      "p=1 for 128/10362\n",
      "total data: 11789\n",
      "total valid data: 10455\n",
      "10455\n",
      "10455\n",
      "10455\n",
      "===Evaluating M_partial on biased data ===\n",
      "\n",
      "*basic estimator*\n",
      "pred_class_list\n",
      "total valid data/total data: 10455/10455\n",
      "sum/count = 121888/10455=11.6583452893\n",
      "upper_bound_list\n",
      "total valid data/total data: 10455/10455\n",
      "sum/count = 103218/10455=9.87259684362\n",
      "\n",
      "*ips+ estimator*\n",
      "pred_class_list\n",
      "sum/count = 121936.0/10455=11.6629363941\n",
      "sum/weights = 121936.0/10459.0=11.6584759537\n",
      "p=1 for 10454/10455\n",
      "upper_bound_list\n",
      "sum/count = 103218.0/10455=9.87259684362\n",
      "sum/weights = 103218.0/10459.0=9.868821111\n",
      "p=1 for 10454/10455\n",
      "\n",
      "pred_class_list\n",
      "sum/count = 609440.0/10455=58.2917264467\n",
      "sum/weights = 609440.0/52275.0=11.6583452893\n",
      "p=1 for 0/10455\n",
      "upper_bound_list\n",
      "sum/count = 515526.0/10455=49.3090387374\n",
      "sum/weights = 515526.0/51719.0=9.9678261374\n",
      "p=1 for 139/10455\n",
      "total data: 11789\n",
      "total valid data: 10518\n",
      "10518\n",
      "10518\n",
      "10518\n",
      "===Evaluating M_partial on biased data ===\n",
      "\n",
      "*basic estimator*\n",
      "pred_class_list\n",
      "total valid data/total data: 10518/10518\n",
      "sum/count = 122184/10518=11.6166571592\n",
      "upper_bound_list\n",
      "total valid data/total data: 10518/10518\n",
      "sum/count = 103513/10518=9.84150979274\n",
      "\n",
      "*ips+ estimator*\n",
      "pred_class_list\n",
      "sum/count = 122232.0/10518=11.6212207644\n",
      "sum/weights = 122232.0/10522.0=11.6168028892\n",
      "p=1 for 10517/10518\n",
      "upper_bound_list\n",
      "sum/count = 103561.0/10518=9.84607339798\n",
      "sum/weights = 103561.0/10522.0=9.84233035545\n",
      "p=1 for 10517/10518\n",
      "\n",
      "pred_class_list\n",
      "sum/count = 610920.0/10518=58.0832857958\n",
      "sum/weights = 610920.0/52590.0=11.6166571592\n",
      "p=1 for 0/10518\n",
      "upper_bound_list\n",
      "sum/count = 517001.0/10518=49.153926602\n",
      "sum/weights = 517001.0/52030.0=9.93659427254\n",
      "p=1 for 140/10518\n"
     ]
    }
   ],
   "source": [
    "# extract biased data from explore\n",
    "dir_name = \"results-0524T1732-learning-1-5ms-deploy-full-explore-3iter\"\n",
    "for index in range(3):\n",
    "    log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/'+str(index)+'/hvmagent.csv'\n",
    "    df = pd.read_csv(log_path) #biased data\n",
    "    lines = []\n",
    "    total_data_count = 0\n",
    "    valid_data_count = 0\n",
    "    logged_class_list = []\n",
    "    correct_class_list = []\n",
    "    current_busy_cpu_list = []\n",
    "    for i in range(len(df.iteration)-1):\n",
    "        correct_class = df.cpu_max[i+1]\n",
    "        pred_class = df.pred_peak[i]\n",
    "        upper_bound = df.upper_bound[i]\n",
    "        current_busy_cpu = df.primary_busy_cores[i]\n",
    "        total_data_count += 1\n",
    "        if upper_bound > correct_class or upper_bound==10:\n",
    "            # overprediction\n",
    "            logged_class_list.append(max(pred_class, current_busy_cpu+1))\n",
    "            correct_class_list.append(correct_class)\n",
    "            current_busy_cpu_list.append(current_busy_cpu)\n",
    "\n",
    "            valid_data_count += 1\n",
    "            features = \"|busy_cores_prev_interval min:\"+str(df.f_min[i])+\" max:\"+str(df.f_max[i]) \\\n",
    "                        +\" avg:\"+str(df.f_avg[i])+\" stddev:\"+str(df.f_stddev[i]) \\\n",
    "                        +\" med:\"+str(df.f_med[i])\n",
    "            #lines.append(features)\n",
    "            '''\n",
    "            for k in range(1,11):\n",
    "                if k<correct_class:\n",
    "                    cost = correct_class-k+10\n",
    "                else:\n",
    "                    cost = k-correct_class\n",
    "                label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "                sample = label+features\n",
    "                lines.append(sample)\n",
    "            '''\n",
    "            k = correct_class\n",
    "            if k<correct_class:\n",
    "                cost = correct_class-k+10\n",
    "            else:\n",
    "                cost = k-correct_class\n",
    "            label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "            sample = label+features\n",
    "            lines.append(sample)\n",
    "\n",
    "    print \"total data: {}\\ntotal valid data: {}\".format(total_data_count, valid_data_count)\n",
    "\n",
    "    outF = open(\"160k/m_partial_biased_data_explore_3iter/\"+str(index)+\"/160k_data.txt\", \"w\")\n",
    "    for line in lines:\n",
    "      # write line to output file\n",
    "      outF.write(line)\n",
    "      outF.write(\"\\n\")\n",
    "    outF.close()\n",
    "\n",
    "    # evaluate m_partial on biased data\n",
    "    file = open(\"160k/m_partial_biased_data_explore_3iter/\"+str(index)+\"/160k_pred_prob.txt\", 'r') \n",
    "    pred_prob_lines = file.readlines() \n",
    "    pred_class_list = []\n",
    "    upper_bound_list = []\n",
    "    for i in range(len(pred_prob_lines)):\n",
    "        line = pred_prob_lines[i]\n",
    "        l = line.strip().split(' ')\n",
    "        for j in range(10):\n",
    "            if float(l[j])==1:\n",
    "                pred=j+1\n",
    "        upper_bound = pred\n",
    "        if i==0:\n",
    "            current_busy_cpu = current_busy_cpu_list[i]\n",
    "        else:\n",
    "            current_busy_cpu = min(current_busy_cpu_list[i], upper_bound_list[i-1])\n",
    "            #current_busy_cpu = current_busy_cpu_list[i]\n",
    "        upper_bound = max(pred, current_busy_cpu+1)\n",
    "        pred_class_list.append(pred)\n",
    "        upper_bound_list.append(upper_bound)\n",
    "        #print \"pred_class={}\\tupper_bound={}\\tcurrent_busy={}\\tcorrect_class{}\".format(pred, upper_bound,current_busy_cpu,correct_class_list[i])\n",
    "\n",
    "    outF = open(\"160k/m_partial_biased_data_explore_3iter/\"+str(index)+\"/160k_pred.txt\", \"w\")\n",
    "    for line in pred_class_list:\n",
    "        # write line to output file\n",
    "        #print line\n",
    "        outF.write(str(line))\n",
    "        outF.write(\"\\n\")\n",
    "    outF.close()\n",
    "\n",
    "    outF = open(\"160k/m_partial_biased_data_explore_3iter/\"+str(index)+\"/160k_upper_bound.txt\", \"w\")\n",
    "    for line in upper_bound_list:\n",
    "        # write line to output file\n",
    "        #print line\n",
    "        outF.write(str(line))\n",
    "        outF.write(\"\\n\")\n",
    "    outF.close()\n",
    "\n",
    "    print len(pred_class_list) # predictions from partial-feedback model\n",
    "    print len(correct_class_list) # correct labels (ground truth)\n",
    "    print len(logged_class_list) # correct labels (ground truth)\n",
    "    assert len(pred_class_list) == len(correct_class_list)\n",
    "    assert len(pred_class_list) == len(logged_class_list)\n",
    "    \n",
    "    print \"===Evaluating M_partial on biased data ===\"\n",
    "    no_harvest = True\n",
    "\n",
    "    print \"\\n*basic estimator*\"\n",
    "    print \"pred_class_list\"\n",
    "    basic_est = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "    print \"upper_bound_list\"\n",
    "    basic_est = basic_estimator(upper_bound_list, correct_class_list, no_harvest)\n",
    "\n",
    "    print \"\\n*ips+ estimator*\"\n",
    "    print \"pred_class_list\"\n",
    "    ips_plus_est = ips_plus_estimator(pred_class_list, correct_class_list, logged_class_list, no_harvest, True)\n",
    "    print \"upper_bound_list\"\n",
    "    ips_plus_est = ips_plus_estimator(upper_bound_list, correct_class_list, logged_class_list, no_harvest, True)\n",
    "\n",
    "    print \"\"\n",
    "    print \"pred_class_list\"\n",
    "    ips_plus_est = ips_plus_estimator(pred_class_list, correct_class_list, logged_class_list, no_harvest, False)\n",
    "    print \"upper_bound_list\"\n",
    "    ips_plus_est = ips_plus_estimator(upper_bound_list, correct_class_list, logged_class_list, no_harvest, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Evaluating M_partial on biased data ===\n",
      "\n",
      "*basic estimator*\n",
      "pred_class_list\n",
      "total valid data/total data: 10385/10385\n",
      "sum/count = 120942/10385=11.6458353394\n",
      "upper_bound_list\n",
      "total valid data/total data: 10385/10385\n",
      "sum/count = 103061/10385=9.92402503611\n",
      "\n",
      "*ips+ estimator*\n",
      "pred_class_list\n",
      "sum/count = 120986.0/10385=11.6500722195\n",
      "sum/weights = 120986.0/10389.0=11.6455866782\n",
      "p=1 for 10384/10385\n",
      "upper_bound_list\n",
      "sum/count = 103105.0/10385=9.92826191623\n",
      "sum/weights = 103105.0/10389.0=9.92443931081\n",
      "p=1 for 10384/10385\n",
      "\n",
      "pred_class_list\n",
      "sum/count = 604710.0/10385=58.2291766972\n",
      "sum/weights = 604710.0/51925.0=11.6458353394\n",
      "p=1 for 0/10385\n",
      "upper_bound_list\n",
      "sum/count = 514713.0/10385=49.5631198844\n",
      "sum/weights = 514713.0/51349.0=10.0238174064\n",
      "p=1 for 144/10385\n"
     ]
    }
   ],
   "source": [
    "print \"===Evaluating M_partial on biased data ===\"\n",
    "no_harvest = True\n",
    "\n",
    "print \"\\n*basic estimator*\"\n",
    "print \"pred_class_list\"\n",
    "basic_est = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "print \"upper_bound_list\"\n",
    "basic_est = basic_estimator(upper_bound_list, correct_class_list, no_harvest)\n",
    "\n",
    "print \"\\n*ips+ estimator*\"\n",
    "print \"pred_class_list\"\n",
    "ips_plus_est = ips_plus_estimator(pred_class_list, correct_class_list, logged_class_list, no_harvest, True)\n",
    "print \"upper_bound_list\"\n",
    "ips_plus_est = ips_plus_estimator(upper_bound_list, correct_class_list, logged_class_list, no_harvest, True)\n",
    "\n",
    "print \"\"\n",
    "print \"pred_class_list\"\n",
    "ips_plus_est = ips_plus_estimator(pred_class_list, correct_class_list, logged_class_list, no_harvest, False)\n",
    "print \"upper_bound_list\"\n",
    "ips_plus_est = ips_plus_estimator(upper_bound_list, correct_class_list, logged_class_list, no_harvest, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ips_plus_estimator(pred_class_list, correct_class_list, logged_class_list, no_harvest, a):\n",
    "    total_classes = 10\n",
    "    count = 0\n",
    "    weights = 0\n",
    "    sum_ = 0\n",
    "    n = total_data_count = len(pred_class_list)\n",
    "    count = 0\n",
    "    count_p1 = 0\n",
    "    for i in range(n):\n",
    "        count += 1;\n",
    "        action_m = pred_class = pred_class_list[i]\n",
    "        correct_class = correct_class_list[i]\n",
    "        if pred_class == correct_class and pred_class != total_classes and not no_harvest:\n",
    "            # correct_class unknown\n",
    "            continue \n",
    "        if pred_class<correct_class:\n",
    "            cost = correct_class-pred_class+total_classes\n",
    "        else:\n",
    "            cost = pred_class-correct_class\n",
    "        #---- compute p ----\n",
    "        full_info_action = correct_class\n",
    "        if a:\n",
    "            a_logging_model = logged_class_list[i]\n",
    "            if a_logging_model > full_info_action:\n",
    "                count_p1 += 1\n",
    "                p = 1\n",
    "                #print \"count (a_logging_model {} > full_info_action {}) is {}\".format(a_logging_model,full_info_action,count_p1)\n",
    "            else:\n",
    "                p = 0.2\n",
    "        else:\n",
    "            if action_m > full_info_action:\n",
    "                count_p1 += 1\n",
    "                p = 1\n",
    "                #print \"count (action_m {} > full_info_action {}) is {}\".format(action_m,full_info_action,count_p1)\n",
    "            else:\n",
    "                p = 0.2\n",
    "\n",
    "        #---- ---- ---- ----\n",
    "        sum_ += cost/p\n",
    "        weights += 1/p\n",
    "        #print \"[pred,target,cost]: [{},{},{}]\".format(pred_class, correct_class, cost)\n",
    "    print \"sum/count = {}/{}={}\".format(sum_, count, sum_/count)\n",
    "    print \"sum/weights = {}/{}={}\".format(sum_, weights, sum_/weights)\n",
    "    print \"p=1 for {}/{}\".format(count_p1, n)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 11856\n",
      "total valid data: 9423\n"
     ]
    }
   ],
   "source": [
    "# extract biased data\n",
    "dir_name = \"results-0522T0733-learning-1-5ms-deploy-full\"\n",
    "log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/0/hvmagent.csv'\n",
    "df = pd.read_csv(log_path) #biased data\n",
    "lines = []\n",
    "total_data_count = 0\n",
    "valid_data_count = 0\n",
    "logged_class_list = []\n",
    "correct_class_list = []\n",
    "current_busy_cpu_list = []\n",
    "for i in range(len(df.iteration)-1):\n",
    "    correct_class = df.cpu_max[i+1]\n",
    "    pred_class = df.pred_peak[i]\n",
    "    upper_bound = df.upper_bound[i]\n",
    "    current_busy_cpu = df.primary_busy_cores[i]\n",
    "    total_data_count += 1\n",
    "    if upper_bound > correct_class or upper_bound==10:\n",
    "        # overprediction\n",
    "        logged_class_list.append(max(pred_class, current_busy_cpu+1))\n",
    "        correct_class_list.append(correct_class)\n",
    "        current_busy_cpu_list.append(current_busy_cpu)\n",
    "        \n",
    "        valid_data_count += 1\n",
    "        features = \"|busy_cores_prev_interval min:\"+str(df.f_min[i])+\" max:\"+str(df.f_max[i]) \\\n",
    "                    +\" avg:\"+str(df.f_avg[i])+\" stddev:\"+str(df.f_stddev[i]) \\\n",
    "                    +\" med:\"+str(df.f_med[i])\n",
    "        #lines.append(features)\n",
    "        '''\n",
    "        for k in range(1,11):\n",
    "            if k<correct_class:\n",
    "                cost = correct_class-k+10\n",
    "            else:\n",
    "                cost = k-correct_class\n",
    "            label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "            sample = label+features\n",
    "            lines.append(sample)\n",
    "        '''\n",
    "        k = correct_class\n",
    "        if k<correct_class:\n",
    "            cost = correct_class-k+10\n",
    "        else:\n",
    "            cost = k-correct_class\n",
    "        label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "        sample = label+features\n",
    "        lines.append(sample)\n",
    "\n",
    "print \"total data: {}\\ntotal valid data: {}\".format(total_data_count, valid_data_count)\n",
    "\n",
    "outF = open(\"160k/m_partial_biased_data/160k_data.txt\", \"w\")\n",
    "for line in lines:\n",
    "  # write line to output file\n",
    "  outF.write(line)\n",
    "  outF.write(\"\\n\")\n",
    "outF.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate m_partial on biased data\n",
    "file = open('160k/m_partial_biased_data/160k_pred_prob.txt', 'r') \n",
    "pred_prob_lines = file.readlines() \n",
    "pred_class_list = []\n",
    "upper_bound_list = []\n",
    "for i in range(len(pred_prob_lines)):\n",
    "    line = pred_prob_lines[i]\n",
    "    l = line.strip().split(' ')\n",
    "    for j in range(10):\n",
    "        if float(l[j])==1:\n",
    "            pred=j+1\n",
    "    upper_bound = pred\n",
    "    if i==0:\n",
    "        current_busy_cpu = current_busy_cpu_list[i]\n",
    "    else:\n",
    "        current_busy_cpu = min(current_busy_cpu_list[i], upper_bound_list[i-1])\n",
    "        #current_busy_cpu = current_busy_cpu_list[i]\n",
    "    upper_bound = max(pred, current_busy_cpu+1)\n",
    "    pred_class_list.append(pred)\n",
    "    upper_bound_list.append(upper_bound)\n",
    "    #print \"pred_class={}\\tupper_bound={}\\tcurrent_busy={}\\tcorrect_class{}\".format(pred, upper_bound,current_busy_cpu,correct_class_list[i])\n",
    "    \n",
    "outF = open(\"160k/m_partial_biased_data/160k_pred.txt\", \"w\")\n",
    "for line in pred_class_list:\n",
    "    # write line to output file\n",
    "    #print line\n",
    "    outF.write(str(line))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()\n",
    "\n",
    "outF = open(\"160k/m_partial_biased_data/160k_upper_bound.txt\", \"w\")\n",
    "for line in upper_bound_list:\n",
    "    # write line to output file\n",
    "    #print line\n",
    "    outF.write(str(line))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Evaluating M_partial on biased data ===\n",
      "\n",
      "*basic estimator*\n",
      "pred_class_list\n",
      "total valid data/total data: 9423/9423\n",
      "sum/count = 109805/9423=11.6528706357\n",
      "upper_bound_list\n",
      "total valid data/total data: 9423/9423\n",
      "sum/count = 93626/9423=9.93590151756\n",
      "\n",
      "*ips+ estimator*\n",
      "pred_class_list\n",
      "sum/count = 109849.0/9423=11.6575400616\n",
      "sum/weights = 109849.0/9427.0=11.6525936141\n",
      "p=1 for 9422/9423\n",
      "upper_bound_list\n",
      "sum/count = 93670.0/9423=9.94057094344\n",
      "sum/weights = 93670.0/9427.0=9.93635302854\n",
      "p=1 for 9422/9423\n",
      "\n",
      "pred_class_list\n",
      "sum/count = 549025.0/9423=58.2643531784\n",
      "sum/weights = 549025.0/47115.0=11.6528706357\n",
      "p=1 for 0/9423\n",
      "upper_bound_list\n",
      "sum/count = 467622.0/9423=49.6255969436\n",
      "sum/weights = 467622.0/46619.0=10.0307170896\n",
      "p=1 for 124/9423\n"
     ]
    }
   ],
   "source": [
    "print \"===Evaluating M_partial on biased data ===\"\n",
    "no_harvest = True\n",
    "\n",
    "print \"\\n*basic estimator*\"\n",
    "print \"pred_class_list\"\n",
    "basic_est = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "print \"upper_bound_list\"\n",
    "basic_est = basic_estimator(upper_bound_list, correct_class_list, no_harvest)\n",
    "\n",
    "print \"\\n*ips+ estimator*\"\n",
    "print \"pred_class_list\"\n",
    "ips_plus_est = ips_plus_estimator(pred_class_list, correct_class_list, logged_class_list, no_harvest, True)\n",
    "print \"upper_bound_list\"\n",
    "ips_plus_est = ips_plus_estimator(upper_bound_list, correct_class_list, logged_class_list, no_harvest, True)\n",
    "\n",
    "print \"\"\n",
    "print \"pred_class_list\"\n",
    "ips_plus_est = ips_plus_estimator(pred_class_list, correct_class_list, logged_class_list, no_harvest, False)\n",
    "print \"upper_bound_list\"\n",
    "ips_plus_est = ips_plus_estimator(upper_bound_list, correct_class_list, logged_class_list, no_harvest, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 11856\n",
      "total valid data: 9849\n",
      "total data: 11854\n",
      "total valid data: 9719\n",
      "total data: 11852\n",
      "total valid data: 9825\n"
     ]
    }
   ],
   "source": [
    "# extract biased data from explore\n",
    "dir_name = \"results-0524T1743-learning-1-5ms-deploy-full-3iter\"\n",
    "for index in range(3):\n",
    "    log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/'+str(index)+'/hvmagent.csv'\n",
    "    df = pd.read_csv(log_path) #biased data\n",
    "    lines = []\n",
    "    total_data_count = 0\n",
    "    valid_data_count = 0\n",
    "    logged_class_list = []\n",
    "    correct_class_list = []\n",
    "    current_busy_cpu_list = []\n",
    "    for i in range(len(df.iteration)-1):\n",
    "        correct_class = df.cpu_max[i+1]\n",
    "        pred_class = df.pred_peak[i]\n",
    "        upper_bound = df.upper_bound[i]\n",
    "        current_busy_cpu = df.primary_busy_cores[i]\n",
    "        total_data_count += 1\n",
    "        if upper_bound > correct_class or upper_bound==10:\n",
    "            # overprediction\n",
    "            logged_class_list.append(max(pred_class, current_busy_cpu+1))\n",
    "            correct_class_list.append(correct_class)\n",
    "            current_busy_cpu_list.append(current_busy_cpu)\n",
    "\n",
    "            valid_data_count += 1\n",
    "            features = \"|busy_cores_prev_interval min:\"+str(df.f_min[i])+\" max:\"+str(df.f_max[i]) \\\n",
    "                        +\" avg:\"+str(df.f_avg[i])+\" stddev:\"+str(df.f_stddev[i]) \\\n",
    "                        +\" med:\"+str(df.f_med[i])\n",
    "            #lines.append(features)\n",
    "            '''\n",
    "            for k in range(1,11):\n",
    "                if k<correct_class:\n",
    "                    cost = correct_class-k+10\n",
    "                else:\n",
    "                    cost = k-correct_class\n",
    "                label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "                sample = label+features\n",
    "                lines.append(sample)\n",
    "            '''\n",
    "            k = correct_class\n",
    "            if k<correct_class:\n",
    "                cost = correct_class-k+10\n",
    "            else:\n",
    "                cost = k-correct_class\n",
    "            label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "            sample = label+features\n",
    "            lines.append(sample)\n",
    "\n",
    "    print \"total data: {}\\ntotal valid data: {}\".format(total_data_count, valid_data_count)\n",
    "\n",
    "    outF = open(\"160k/m_partial_biased_data_3iter/\"+str(index)+\"/160k_data.txt\", \"w\")\n",
    "    for line in lines:\n",
    "      # write line to output file\n",
    "      outF.write(line)\n",
    "      outF.write(\"\\n\")\n",
    "    outF.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 11856\n",
      "total valid data: 9849\n",
      "9849\n",
      "9849\n",
      "9849\n",
      "===Evaluating M_partial on biased data ===\n",
      "\n",
      "*basic estimator*\n",
      "pred_class_list\n",
      "total valid data/total data: 9849/9849\n",
      "sum/count = 117079/9849=11.887399736\n",
      "upper_bound_list\n",
      "total valid data/total data: 9849/9849\n",
      "sum/count = 102798/9849=10.4374048127\n",
      "\n",
      "*ips+ estimator*\n",
      "pred_class_list\n",
      "sum/count = 117127.0/9849=11.8922733272\n",
      "sum/weights = 117127.0/9853.0=11.8874454481\n",
      "p=1 for 9848/9849\n",
      "upper_bound_list\n",
      "sum/count = 102798.0/9849=10.4374048127\n",
      "sum/weights = 102798.0/9853.0=10.4331675632\n",
      "p=1 for 9848/9849\n",
      "\n",
      "pred_class_list\n",
      "sum/count = 585395.0/9849=59.4369986801\n",
      "sum/weights = 585395.0/49245.0=11.887399736\n",
      "p=1 for 0/9849\n",
      "upper_bound_list\n",
      "sum/count = 513654.0/9849=52.1529089248\n",
      "sum/weights = 513654.0/48917.0=10.5005212912\n",
      "p=1 for 82/9849\n",
      "total data: 11854\n",
      "total valid data: 9719\n",
      "9719\n",
      "9719\n",
      "9719\n",
      "===Evaluating M_partial on biased data ===\n",
      "\n",
      "*basic estimator*\n",
      "pred_class_list\n",
      "total valid data/total data: 9719/9719\n",
      "sum/count = 115587/9719=11.892890215\n",
      "upper_bound_list\n",
      "total valid data/total data: 9719/9719\n",
      "sum/count = 100855/9719=10.3770964091\n",
      "\n",
      "*ips+ estimator*\n",
      "pred_class_list\n",
      "sum/count = 115639.0/9719=11.8982405597\n",
      "sum/weights = 115639.0/9723.0=11.8933456752\n",
      "p=1 for 9718/9719\n",
      "upper_bound_list\n",
      "sum/count = 100903.0/9719=10.3820351888\n",
      "sum/weights = 100903.0/9723.0=10.3777640646\n",
      "p=1 for 9718/9719\n",
      "\n",
      "pred_class_list\n",
      "sum/count = 577935.0/9719=59.4644510752\n",
      "sum/weights = 577935.0/48595.0=11.892890215\n",
      "p=1 for 0/9719\n",
      "upper_bound_list\n",
      "sum/count = 503891.0/9719=51.8459718078\n",
      "sum/weights = 503891.0/48215.0=10.4509177642\n",
      "p=1 for 95/9719\n",
      "total data: 11852\n",
      "total valid data: 9825\n",
      "9825\n",
      "9825\n",
      "9825\n",
      "===Evaluating M_partial on biased data ===\n",
      "\n",
      "*basic estimator*\n",
      "pred_class_list\n",
      "total valid data/total data: 9825/9825\n",
      "sum/count = 116831/9825=11.8911959288\n",
      "upper_bound_list\n",
      "total valid data/total data: 9825/9825\n",
      "sum/count = 101720/9825=10.3531806616\n",
      "\n",
      "*ips+ estimator*\n",
      "pred_class_list\n",
      "sum/count = 116879.0/9825=11.8960814249\n",
      "sum/weights = 116879.0/9829.0=11.8912402075\n",
      "p=1 for 9824/9825\n",
      "upper_bound_list\n",
      "sum/count = 101764.0/9825=10.3576590331\n",
      "sum/weights = 101764.0/9829.0=10.3534438905\n",
      "p=1 for 9824/9825\n",
      "\n",
      "pred_class_list\n",
      "sum/count = 584155.0/9825=59.4559796438\n",
      "sum/weights = 584155.0/49125.0=11.8911959288\n",
      "p=1 for 0/9825\n",
      "upper_bound_list\n",
      "sum/count = 508236.0/9825=51.7288549618\n",
      "sum/weights = 508236.0/48769.0=10.4212922143\n",
      "p=1 for 89/9825\n"
     ]
    }
   ],
   "source": [
    "# extract biased data\n",
    "dir_name = \"results-0524T1743-learning-1-5ms-deploy-full-3iter\"\n",
    "for index in range(3):\n",
    "    log_path = '160k/logs/'+dir_name+'/SmartIPI_HOLES-0.1-sleep_ms/buf-1/'+str(index)+'/hvmagent.csv'\n",
    "    df = pd.read_csv(log_path) #biased data\n",
    "    lines = []\n",
    "    total_data_count = 0\n",
    "    valid_data_count = 0\n",
    "    logged_class_list = []\n",
    "    correct_class_list = []\n",
    "    current_busy_cpu_list = []\n",
    "    for i in range(len(df.iteration)-1):\n",
    "        correct_class = df.cpu_max[i+1]\n",
    "        pred_class = df.pred_peak[i]\n",
    "        upper_bound = df.upper_bound[i]\n",
    "        current_busy_cpu = df.primary_busy_cores[i]\n",
    "        total_data_count += 1\n",
    "        if upper_bound > correct_class or upper_bound==10:\n",
    "            # overprediction\n",
    "            logged_class_list.append(max(pred_class, current_busy_cpu+1))\n",
    "            correct_class_list.append(correct_class)\n",
    "            current_busy_cpu_list.append(current_busy_cpu)\n",
    "\n",
    "            valid_data_count += 1\n",
    "            features = \"|busy_cores_prev_interval min:\"+str(df.f_min[i])+\" max:\"+str(df.f_max[i]) \\\n",
    "                        +\" avg:\"+str(df.f_avg[i])+\" stddev:\"+str(df.f_stddev[i]) \\\n",
    "                        +\" med:\"+str(df.f_med[i])\n",
    "            #lines.append(features)\n",
    "            '''\n",
    "            for k in range(1,11):\n",
    "                if k<correct_class:\n",
    "                    cost = correct_class-k+10\n",
    "                else:\n",
    "                    cost = k-correct_class\n",
    "                label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "                sample = label+features\n",
    "                lines.append(sample)\n",
    "            '''\n",
    "            k = correct_class\n",
    "            if k<correct_class:\n",
    "                cost = correct_class-k+10\n",
    "            else:\n",
    "                cost = k-correct_class\n",
    "            label = str(k)+\":\"+str(cost)+\":1 \"\n",
    "            sample = label+features\n",
    "            lines.append(sample)\n",
    "\n",
    "    print \"total data: {}\\ntotal valid data: {}\".format(total_data_count, valid_data_count)\n",
    "\n",
    "    outF = open(\"160k/m_partial_biased_data_3iter/\"+str(index)+\"/160k_data.txt\", \"w\")\n",
    "    for line in lines:\n",
    "      # write line to output file\n",
    "      outF.write(line)\n",
    "      outF.write(\"\\n\")\n",
    "    outF.close()\n",
    "\n",
    "    # evaluate m_partial on biased data\n",
    "    file = open(\"160k/m_partial_biased_data_3iter/\"+str(index)+\"/160k_pred_prob.txt\", 'r') \n",
    "    pred_prob_lines = file.readlines() \n",
    "    pred_class_list = []\n",
    "    upper_bound_list = []\n",
    "    for i in range(len(pred_prob_lines)):\n",
    "        line = pred_prob_lines[i]\n",
    "        l = line.strip().split(' ')\n",
    "        for j in range(10):\n",
    "            if float(l[j])==1:\n",
    "                pred=j+1\n",
    "        upper_bound = pred\n",
    "        if i==0:\n",
    "            current_busy_cpu = current_busy_cpu_list[i]\n",
    "        else:\n",
    "            current_busy_cpu = min(current_busy_cpu_list[i], upper_bound_list[i-1])\n",
    "            #current_busy_cpu = current_busy_cpu_list[i]\n",
    "        upper_bound = max(pred, current_busy_cpu+1)\n",
    "        pred_class_list.append(pred)\n",
    "        upper_bound_list.append(upper_bound)\n",
    "        #print \"pred_class={}\\tupper_bound={}\\tcurrent_busy={}\\tcorrect_class{}\".format(pred, upper_bound,current_busy_cpu,correct_class_list[i])\n",
    "\n",
    "    outF = open(\"160k/m_partial_biased_data_3iter/\"+str(index)+\"/160k_pred.txt\", \"w\")\n",
    "    for line in pred_class_list:\n",
    "        # write line to output file\n",
    "        #print line\n",
    "        outF.write(str(line))\n",
    "        outF.write(\"\\n\")\n",
    "    outF.close()\n",
    "\n",
    "    outF = open(\"160k/m_partial_biased_data_3iter/\"+str(index)+\"/160k_upper_bound.txt\", \"w\")\n",
    "    for line in upper_bound_list:\n",
    "        # write line to output file\n",
    "        #print line\n",
    "        outF.write(str(line))\n",
    "        outF.write(\"\\n\")\n",
    "    outF.close()\n",
    "\n",
    "    print len(pred_class_list) # predictions from partial-feedback model\n",
    "    print len(correct_class_list) # correct labels (ground truth)\n",
    "    print len(logged_class_list) # correct labels (ground truth)\n",
    "    assert len(pred_class_list) == len(correct_class_list)\n",
    "    assert len(pred_class_list) == len(logged_class_list)\n",
    "    \n",
    "    print \"===Evaluating M_partial on biased data ===\"\n",
    "    no_harvest = True\n",
    "\n",
    "    print \"\\n*basic estimator*\"\n",
    "    print \"pred_class_list\"\n",
    "    basic_est = basic_estimator(pred_class_list, correct_class_list, no_harvest)\n",
    "    print \"upper_bound_list\"\n",
    "    basic_est = basic_estimator(upper_bound_list, correct_class_list, no_harvest)\n",
    "\n",
    "    print \"\\n*ips+ estimator*\"\n",
    "    print \"pred_class_list\"\n",
    "    ips_plus_est = ips_plus_estimator(pred_class_list, correct_class_list, logged_class_list, no_harvest, True)\n",
    "    print \"upper_bound_list\"\n",
    "    ips_plus_est = ips_plus_estimator(upper_bound_list, correct_class_list, logged_class_list, no_harvest, True)\n",
    "\n",
    "    print \"\"\n",
    "    print \"pred_class_list\"\n",
    "    ips_plus_est = ips_plus_estimator(pred_class_list, correct_class_list, logged_class_list, no_harvest, False)\n",
    "    print \"upper_bound_list\"\n",
    "    ips_plus_est = ips_plus_estimator(upper_bound_list, correct_class_list, logged_class_list, no_harvest, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
